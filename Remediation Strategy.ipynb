{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "from scipy.stats import randint as sp_randint\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choices\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>iq</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>92.472816</td>\n",
       "      <td>959.728157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>77.055728</td>\n",
       "      <td>862.557282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>96.986655</td>\n",
       "      <td>1046.866552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>104.129996</td>\n",
       "      <td>1105.299959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>101.215587</td>\n",
       "      <td>1047.155871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit          iq          sat\n",
       "0  False   92.472816   959.728157\n",
       "1  False   77.055728   862.557282\n",
       "2  False   96.986655  1046.866552\n",
       "3  False  104.129996  1105.299959\n",
       "4  False  101.215587  1047.155871"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic = pd.read_csv(\"synthetic.csv\")\n",
    "synthetic.pop('gender')\n",
    "synthetic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>iq</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.404000</td>\n",
       "      <td>100.037458</td>\n",
       "      <td>1045.088979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.490747</td>\n",
       "      <td>19.909603</td>\n",
       "      <td>201.439475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.912771</td>\n",
       "      <td>271.127706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.664101</td>\n",
       "      <td>908.881888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.936357</td>\n",
       "      <td>1040.152307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>113.993465</td>\n",
       "      <td>1185.707223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.906606</td>\n",
       "      <td>1688.765366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             admit           iq          sat\n",
       "count  5000.000000  5000.000000  5000.000000\n",
       "mean      0.404000   100.037458  1045.088979\n",
       "std       0.490747    19.909603   201.439475\n",
       "min       0.000000    23.912771   271.127706\n",
       "25%       0.000000    86.664101   908.881888\n",
       "50%       0.000000    99.936357  1040.152307\n",
       "75%       1.000000   113.993465  1185.707223\n",
       "max       1.000000   159.906606  1688.765366"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic['admit'] = [0 if x == False else 1 for x in synthetic['admit']]\n",
    "synthetic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_Fx(df_p,df_n,ppc, npc):\n",
    "    \"\"\"\n",
    "    \n",
    "    Add sensitive feature {0,1} to the dataframe\n",
    "    \n",
    "    parameter:\n",
    "    - df_p   : dataframe for Y = 1\n",
    "    - df_n   : dataframe for Y = 0\n",
    "    - ppc    : percentage of S = 1 in Y = 0\n",
    "    - npc    : percentage of S = 1 in Y = 0\n",
    "    \n",
    "    output:\n",
    "    - X      : 8-dim array of independent variable\n",
    "    - y      : 1-dim array of target variable\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    df_p.loc[:, 'Feature_X'] = choices([0,1],cum_weights = [ppc,100], k = len(df_p))\n",
    "    df_n.loc[:, 'Feature_X'] = choices([0,1],cum_weights = [npc,100], k = len(df_n))\n",
    "    dall = df_p.append(df_n)   \n",
    "    \n",
    "#     print(\"Distribution of Sensitive Attribute in Y = 1: {}\".format(Counter(df_p['Feature_X'])))\n",
    "#     print(\"Distribution of Sensitive Attribute in Y = 0: {}\".format(Counter(df_n['Feature_X'])))\n",
    "#     print(\"Distribution of Y (total): {}\".format(Counter(dall['Class'])))\n",
    "#     print(\"Distribution of Sensitive Attribute in Y (total): {}\".format(Counter(dall['Feature_X'])))\n",
    "    y = dall.pop(\"admit\").values\n",
    "    X = dall.values\n",
    "    #print(\"Dimension of X after adding sensitive attribute: {}\".format(X.shape))\n",
    "    #print(\"Shape of y: {}\".format(y.shape))\n",
    "    return X, y \n",
    "\n",
    "def df_subsample_pos_class(all_df, rpc = 0, subsample = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Add sensitive feature {0,1} to the dataframe\n",
    "    \n",
    "    parameter:\n",
    "    - all_df : original dataframe\n",
    "    - rpc    : requested positive percentage to subsample\n",
    "    \n",
    "    output:\n",
    "    - df_p      : dataframe for Y = 1 after subsampling\n",
    "    - df_n      : dataframe for Y = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if subsample :\n",
    "        rp = rpc/100 \n",
    "        df_p = all_df[all_df['admit']==1].copy()\n",
    "        df_n = all_df[all_df['admit']==0].copy()\n",
    "        np = len(df_p)\n",
    "        nn = len(df_n)\n",
    "        perc_p = np/(np+nn)\n",
    "    \n",
    "        if rp > perc_p:\n",
    "            print('Requested positive percentage (pcpc) is too high.',perc_p)\n",
    "            return df_p, df_n\n",
    "    \n",
    "        np_dash = rp/(1-rp)* nn\n",
    "        df_p = df_p.sample(int(np_dash+0.5))\n",
    "    \n",
    "        #print(np,nn,'--',np_dash)\n",
    "        return df_p, df_n\n",
    "    else:\n",
    "        df_p = all_df[all_df['admit']==1].copy()\n",
    "        df_n = all_df[all_df['admit']==0].copy()\n",
    "        return df_p,df_n\n",
    "\n",
    "def oversample_minority_smote_adasyn(X_N,Y_N,X_P,Y_P):\n",
    "\n",
    "    #oversample (SMOTE) minority for both y=0 and y=1\n",
    "    X_N_smote, Y_N_smote = SMOTE(sampling_strategy='minority',n_jobs=-1,random_state=0).fit_resample(X_N, Y_N)\n",
    "    X_P_smote, Y_P_smote = SMOTE(sampling_strategy='minority',n_jobs=-1,random_state=0).fit_resample(X_P, Y_P)\n",
    "    X_N_smote['sex'] = Y_N_smote\n",
    "    X_N_smote['admit'] = np.zeros(Y_N_smote.shape)\n",
    "    X_P_smote['sex'] = Y_P_smote\n",
    "    X_P_smote['admit'] = np.ones(Y_P_smote.shape)\n",
    "    train_smote = pd.concat([X_N_smote,X_P_smote])\n",
    "\n",
    "    #get xtrain and ytrain for SMOTE\n",
    "    y_train_smote = train_smote['admit']\n",
    "    train_smote.pop('admit')\n",
    "    Xtrain_smote = train_smote\n",
    "    \n",
    "    return Xtrain_smote,y_train_smote\n",
    "    \n",
    "def df_count_feat_val_match(df1, f1, v1, f2, v2):\n",
    "    return len (df1[(df1[f1]==int(v1)) & (df1[f2]==int(v2))])\n",
    "\n",
    "def optimize_model(clf,param,Xtrain,Xtest,y_train,y_test,scoring,cv):\n",
    "    grid = RandomizedSearchCV(clf,param,cv=cv,scoring=scoring,n_jobs=-1,n_iter=50)\n",
    "    grid.fit(Xtrain,y_train)\n",
    "#     print(\"Classifier: {}\".format(clf.__class__.__name__))\n",
    "#     print(\"Best parameter: {}\".format(grid.best_params_))\n",
    "#     print(\"Best {}: {}\".format(str(scoring),grid.best_score_))\n",
    "#     print(\"-\"*30)\n",
    "    y_pred = grid.predict(Xtest)\n",
    "    return y_pred,grid.best_params_\n",
    "\n",
    "## return best param\n",
    "## return best score\n",
    "\n",
    "def underestimation_score(y_true,y_pred,SA):\n",
    "    \"\"\"\n",
    "    \n",
    "    parameter:\n",
    "    - y_true : ground truth for prediction outcomes\n",
    "    - y_pred : predicted outcomes\n",
    "    - SA     : sensitive attributes\n",
    "    \n",
    "    output:\n",
    "    - us_0: underestimation for S = 0\n",
    "    - us_1: underestimation for S = 1\n",
    "    \n",
    "    \"\"\"\n",
    "    mydict = {}\n",
    "    mydict['actual'] = y_true\n",
    "    mydict['predicted'] = y_pred\n",
    "    mydict['sex'] = SA\n",
    "    us = pd.DataFrame(mydict)\n",
    "\n",
    "    P_dash_FX0 = df_count_feat_val_match(us, 'predicted', 1, 'sex',0)\n",
    "    P_FX0 = df_count_feat_val_match(us, 'actual', 1, 'sex',0)\n",
    "    Bias_FX0 = P_dash_FX0/P_FX0\n",
    "    \n",
    "    if P_FX0 == 0:\n",
    "        print(\"Divsion by zero detected!\")\n",
    "               \n",
    "    return Bias_FX0\n",
    "\n",
    "def evaluate_model(y_true,y_pred,SA):\n",
    "    \"\"\"\n",
    "    \n",
    "    parameter:\n",
    "    - y_true : ground truth for prediction outcomes\n",
    "    - y_pred : predicted labels\n",
    "    - y_prob : predicted probability\n",
    "    - SA     : sensitive attributes in the test data\n",
    "    \n",
    "    output:\n",
    "    - accuracy : accuracy scores\n",
    "    - rocauc   : roc auc scores\n",
    "    - us_0     : underestimation score for S = 0\n",
    "    - us_1     : underestimation score for S = 1\n",
    "    \n",
    "    \"\"\"\n",
    "    Counter\n",
    "    accuracy = balanced_accuracy_score(y_true,y_pred)\n",
    "    b = underestimation_score(y_true,y_pred,SA)\n",
    "\n",
    "    \n",
    "    ## add counter for SA\n",
    "    ## add counter for class imbalance\n",
    "    ## add TP TN etc\n",
    "    \n",
    "    return accuracy,b\n",
    "\n",
    "\n",
    "    \n",
    "def preprocess_data(X,y):\n",
    "    \"\"\"\n",
    "    Numerical features are scaled using MinMaxScaler, while categorical features one-hot-encoded.\n",
    "    \n",
    "    parameter:\n",
    "    - X    : 8-dim array of independent variable\n",
    "    - y    : 1-dim array of target variable\n",
    "    \n",
    "    output:\n",
    "    - Xtrain      : 8-dim array containing independent variable in the train test\n",
    "    - Xtest       : 8-dim array containing independent variable in the test set\n",
    "    - y_train     : 1-dim array of target variable in the train set\n",
    "    - y_test      : 1-dim array of target variable in the test set\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    minority_in_Pos = 0\n",
    "    \n",
    "    while not minority_in_Pos:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = True, stratify = y)\n",
    "        temp = pd.DataFrame({'Feature_X': X_test[:,2], 'admit': y_test}, columns=['Feature_X', 'admit'])\n",
    "#         print(df_count_feat_val_match(temp, 'admit', 1, 'Feature_X',0) )\n",
    "        minority_in_Pos = df_count_feat_val_match(temp, 'admit', 1, 'Feature_X',0)    \n",
    "\n",
    "    minmax = MinMaxScaler()\n",
    "    xtrain_num = minmax.fit_transform(X_train[:,0:2])\n",
    "    xtest_num = minmax.transform(X_test[:,0:2])\n",
    "    \n",
    "    Xtrain = np.hstack((xtrain_num,X_train[:,2].reshape(-1,1)))\n",
    "    Xtest = np.hstack((xtest_num,X_test[:,2].reshape(-1,1)))\n",
    "\n",
    "#     print(\"Shape of train data: {}\".format(Xtrain.shape))\n",
    "#     print(\"Shape of test data : {}\".format(Xtest.shape))\n",
    "    \n",
    "    return Xtrain,Xtest,y_train,y_test\n",
    "\n",
    "def US_scorer(clf, X_tst, y_tst):\n",
    "    y_pred = clf.predict(X_tst)\n",
    "    Fx_tst = [int(i) for i in X_tst[:,-1]]\n",
    "    US_s = underestimation_score(y_tst,y_pred,Fx_tst)\n",
    "    try:\n",
    "        US = 1/(abs(1-US_s))\n",
    "    except:\n",
    "        US= 1/(abs((1-US_s))+0.0001)\n",
    "    return US\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def custom_loss_function(clf,X_tst,y_test):\n",
    "    y_pred = clf.predict(X_tst)\n",
    "    Fx_tst = [int(i) for i in X_tst[:,-1]]\n",
    "    \n",
    "    US_s = underestimation_score(y_test,y_pred,Fx_tst)\n",
    "    try:\n",
    "        US = 1/(abs(1-US_s))\n",
    "    except:\n",
    "#         print(\"smoothing added\")\n",
    "        US= 1/(abs((1-US_s))+0.0001)\n",
    "\n",
    "    accuracy = balanced_accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    weight_ACC = 0.5\n",
    "    \n",
    "    return (weight_ACC*accuracy) + ((1-weight_ACC) * US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = MLPClassifier(random_state=0,max_iter=20000) \n",
    "params = {'hidden_layer_sizes': sp_randint(1, 200),\\\n",
    "          'activation':['tanh','relu','logistic'],'solver':['adam','sgd'],\\\n",
    "                        'alpha':stats.reciprocal(a=1e-7,b=1e2), 'learning_rate': ['constant','adaptive']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2980, 1: 2020}\n",
      "Percent of positive labels (Y = 1): 33.89%\n"
     ]
    }
   ],
   "source": [
    "counts = synthetic['admit'].value_counts().to_dict()\n",
    "print(counts)\n",
    "MCPc = counts[1]/(counts[0]+counts[0])*100\n",
    "print(\"Percent of positive labels (Y = 1): {0:.2f}%\".format(MCPc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 50)\n",
      ">> 1\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6614029201977916 0.6516883760958035 0.667936169902417 0.658603789547384\n",
      "Underestimation:\n",
      "0.8216216216216217 0.5513513513513514 0.8540540540540541 0.7891891891891892\n",
      ">> 2\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6658780285018306 0.6520472015986697 0.6709176305847688 0.6757749026357629\n",
      "Underestimation:\n",
      "0.825136612021858 0.5245901639344263 0.8743169398907104 0.9180327868852459\n",
      ">> 3\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.667530667911373 0.6645375381069767 0.6751870706127748 0.6764867190804732\n",
      "Underestimation:\n",
      "0.7675675675675676 0.5459459459459459 0.7837837837837838 0.7675675675675676\n",
      ">> 4\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6710766223726242 0.6507358840089269 0.6703297985617807 0.6641728780430882\n",
      "Underestimation:\n",
      "0.7377049180327869 0.5409836065573771 0.726775956284153 0.7049180327868853\n",
      ">> 5\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6593564479192496 0.6487127499744738 0.6672068497746401 0.6517058797788702\n",
      "Underestimation:\n",
      "0.847953216374269 0.5614035087719298 0.9707602339181286 0.8538011695906432\n",
      ">> 6\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.685636769403562 0.6643552080750325 0.6740697521770206 0.6873185816182155\n",
      "Underestimation:\n",
      "0.7868020304568528 0.5228426395939086 0.7258883248730964 0.8324873096446701\n",
      ">> 7\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6513412197149817 0.6229677494639497 0.6489125836894847 0.652458538150736\n",
      "Underestimation:\n",
      "0.8757062146892656 0.5649717514124294 0.8757062146892656 0.8813559322033898\n",
      ">> 8\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6496535729393059 0.642926324080692 0.631547471447117 0.6442434762314571\n",
      "Underestimation:\n",
      "0.734375 0.5625 0.734375 0.7864583333333334\n",
      ">> 9\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6559869889289205 0.6524468690286914 0.6731522674562772 0.6681126653733389\n",
      "Underestimation:\n",
      "0.6116504854368932 0.529126213592233 0.7524271844660194 0.7427184466019418\n",
      ">> 10\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6498125647271613 0.6477660924486194 0.6679303353413948 0.6619557448546465\n",
      "Underestimation:\n",
      "0.7039106145251397 0.5363128491620112 0.8212290502793296 0.8044692737430168\n",
      ">> 11\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6578628002975626 0.6507533876919935 0.6621672476917018 0.662349577723646\n",
      "Underestimation:\n",
      "0.8167539267015707 0.5445026178010471 0.8952879581151832 0.8586387434554974\n",
      ">> 12\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6677305016263839 0.6511122131948598 0.6686654900301938 0.6669836778155404\n",
      "Underestimation:\n",
      "0.7027027027027027 0.4540540540540541 0.7135135135135136 0.7081081081081081\n",
      ">> 13\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6513237160319151 0.6434849832985691 0.6539463512114008 0.6565514827078198\n",
      "Underestimation:\n",
      "0.7458563535911602 0.574585635359116 0.7955801104972375 0.7513812154696132\n",
      ">> 14\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6483305862275187 0.6285485070816984 0.6466662776959318 0.6481540907565967\n",
      "Underestimation:\n",
      "0.6021505376344086 0.3924731182795699 0.6612903225806451 0.6612903225806451\n",
      ">> 15\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6699826421809589 0.6513237160319151 0.6660603585337749 0.6705413013988359\n",
      "Underestimation:\n",
      "0.7368421052631579 0.5473684210526316 0.7315789473684211 0.7526315789473684\n",
      ">> 16\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6593447787972053 0.6416150064909492 0.6666248523126741 0.6636433916303222\n",
      "Underestimation:\n",
      "0.678391959798995 0.49748743718592964 0.7839195979899497 0.7437185929648241\n",
      ">> 17\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.63994486339834 0.622597254839039 0.6382572166226643 0.6472307714748311\n",
      "Underestimation:\n",
      "0.6231155778894473 0.457286432160804 0.6532663316582915 0.7135678391959799\n",
      ">> 18\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6500123984421722 0.6246262234345143 0.65000656388115 0.6580334612074624\n",
      "Underestimation:\n",
      "0.6363636363636364 0.41414141414141414 0.6767676767676768 0.6818181818181818\n",
      ">> 19\n",
      "SMOTE done!\n",
      "Accuracy:\n",
      "0.6675481715944397 0.6490657409163179 0.6662485231267412 0.6669895123765626\n",
      "Underestimation:\n",
      "0.7566137566137566 0.5132275132275133 0.7724867724867724 0.7671957671957672\n",
      ">> 20\n",
      "SMOTE done!\n"
     ]
    }
   ],
   "source": [
    "class_incidence = [30]\n",
    "feature_incidence = [50]\n",
    "heatmap_DF = {}\n",
    "result = []\n",
    "result_1 = []\n",
    "result_2 = []\n",
    "result_3 = []\n",
    "\n",
    "best_model = {}\n",
    "\n",
    "\n",
    "temp_heatmap = pd.DataFrame(columns=feature_incidence)\n",
    "temp_heatmap_1 = pd.DataFrame(columns=feature_incidence)\n",
    "temp_heatmap_2 = pd.DataFrame(columns=feature_incidence)\n",
    "temp_heatmap_3 = pd.DataFrame(columns=feature_incidence)\n",
    "\n",
    "acc_heatmap = pd.DataFrame(columns=feature_incidence)\n",
    "acc_heatmap_1 = pd.DataFrame(columns=feature_incidence)\n",
    "acc_heatmap_2 = pd.DataFrame(columns=feature_incidence)\n",
    "acc_heatmap_3 = pd.DataFrame(columns=feature_incidence)\n",
    "\n",
    "for class_imb in class_incidence:\n",
    "    accuracies = []\n",
    "    biases = []\n",
    "    accuracies_1 = []\n",
    "    biases_1 = []\n",
    "    accuracies_2 = []\n",
    "    biases_2 = []\n",
    "    accuracies_3 = []\n",
    "    biases_3 = []\n",
    "    for feature_imb in feature_incidence:\n",
    "        print((class_imb,feature_imb))\n",
    "            \n",
    "        df_p,df_n = df_subsample_pos_class(synthetic,class_imb)\n",
    "        X,y = add_Fx(df_p,df_n,feature_imb,40)\n",
    "        \n",
    "        acc = []\n",
    "        bias = []\n",
    "        acc_1 = []\n",
    "        bias_1 = []\n",
    "        acc_2 = []\n",
    "        bias_2 = []\n",
    "        acc_3 = []\n",
    "        bias_3 = [] \n",
    "        \n",
    "        for n in range(20):\n",
    "        #progress bar\n",
    "            print(\">> {}\".format(n+1))\n",
    "            \n",
    "            for xx in range(20):\n",
    "                    try:\n",
    "                        Xtrain,Xtest,y_train,y_test = preprocess_data(X,y)\n",
    "                        y_pred,b_ = optimize_model(models,params,Xtrain,Xtest,y_train,y_test,'balanced_accuracy',10)\n",
    "                        break\n",
    "                    except:\n",
    "                        print(\"{} - Division by zero detected!\",format(xx))\n",
    "                        pass   \n",
    "            \n",
    "            \n",
    "            #dataset description\n",
    "            train = pd.DataFrame(np.hstack((Xtrain,np.array(y_train).reshape(-1,1))), columns=['IQ', 'SAT','sex','admit'])\n",
    "            NF = train[(train['sex']==0) & (train['admit']==0)]\n",
    "            NM = train[(train['sex']==1) & (train['admit']==0)]\n",
    "            PF = train[(train['sex']==0) & (train['admit']==1)]\n",
    "            PM = train[(train['sex']==1) & (train['admit']==1)]\n",
    "            # split dataset by classes\n",
    "            N = pd.concat([NF.iloc[:,0:8],NM.iloc[:,0:8]])\n",
    "            Y_N = N['sex']\n",
    "            N.pop('sex')\n",
    "            X_N = N\n",
    "            P = pd.concat([PF.iloc[:,0:8],PM.iloc[:,0:8]])\n",
    "            Y_P = P['sex']\n",
    "            P.pop('sex')\n",
    "            X_P = P\n",
    "            \n",
    "            \n",
    "            #SMOTE\n",
    "            Xtrain_smote,y_train_smote = oversample_minority_smote_adasyn(X_N,Y_N,X_P,Y_P)\n",
    "            y_pred_1,_ = optimize_model(models,params,Xtrain_smote,Xtest,y_train_smote,y_test,'balanced_accuracy',10)\n",
    "            print(\"SMOTE done!\")\n",
    "            \n",
    "            #Counterfactual-1\n",
    "            to_be_sampled = abs(PM.shape[0]-PF.shape[0])\n",
    "            sampled_NF = NF.sample(n=to_be_sampled, random_state=1)\n",
    "            sampled_NF['admit'] = np.ones(to_be_sampled)\n",
    "            counterfactual_1 = pd.concat([sampled_NF,PF,PM,NF,NM])\n",
    "            y_train_counterfactual_1 = counterfactual_1['admit']\n",
    "            counterfactual_1.pop('admit')\n",
    "            Xtrain_counterfactual_1 = counterfactual_1\n",
    "            y_pred_2,_ = optimize_model(models,params,Xtrain_counterfactual_1,Xtest,y_train_counterfactual_1,y_test,'balanced_accuracy',10)\n",
    "\n",
    "                                        \n",
    "            ## counterfactual - 2\n",
    "            sampled_PM = PM.sample(n=to_be_sampled, random_state=1)\n",
    "            sampled_PM['sex'] = np.zeros(to_be_sampled)\n",
    "            sampled_PM['admit'] = np.ones(to_be_sampled)\n",
    "            counterfactual_2 = pd.concat([sampled_PM,PF,PM,NF,NM])\n",
    "            y_train_counterfactual_2 = counterfactual_2['admit']\n",
    "            counterfactual_2.pop('admit')\n",
    "            Xtrain_counterfactual_2 = counterfactual_2\n",
    "            y_pred_3,_ = optimize_model(models,params,Xtrain_counterfactual_2,Xtest,y_train_counterfactual_2,y_test,'balanced_accuracy',10)\n",
    "                           \n",
    "            accuracy,bi = evaluate_model(y_test,y_pred,Xtest[:,2].ravel()) \n",
    "            accuracy_1,bi_1 = evaluate_model(y_test,y_pred_1,Xtest[:,2].ravel()) \n",
    "            accuracy_2,bi_2 = evaluate_model(y_test,y_pred_2,Xtest[:,2].ravel())\n",
    "            accuracy_3,bi_3 = evaluate_model(y_test,y_pred_3,Xtest[:,2].ravel())\n",
    "            \n",
    "            print(\"Accuracy:\")\n",
    "            print(accuracy,accuracy_1,accuracy_2,accuracy_3) \n",
    "            print(\"Underestimation:\")\n",
    "            print(bi,bi_1,bi_2,bi_3)\n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "            acc.append(accuracy)\n",
    "            bias.append(bi)\n",
    "            acc_1.append(accuracy_1)\n",
    "            bias_1.append(bi_1)\n",
    "            acc_2.append(accuracy_2)\n",
    "            bias_2.append(bi_2)\n",
    "            acc_3.append(accuracy_3)\n",
    "            bias_3.append(bi_3)            \n",
    "            \n",
    "        accuracies.append(np.median(acc))\n",
    "        biases.append(np.median(bias))\n",
    "        accuracies_1.append(np.median(acc_1))\n",
    "        biases_1.append(np.median(bias_1))\n",
    "        accuracies_2.append(np.median(acc_2))\n",
    "        biases_2.append(np.median(bias_2))\n",
    "        accuracies_3.append(np.median(acc_3))\n",
    "        biases_3.append(np.median(bias_3))\n",
    "        result.append([class_imb,feature_imb,np.median(acc),np.median(bias)])\n",
    "        result_1.append([class_imb,feature_imb,np.median(acc_1),np.median(bias_1)])\n",
    "        result_2.append([class_imb,feature_imb,np.median(acc_2),np.median(bias_2)])\n",
    "        result_3.append([class_imb,feature_imb,np.median(acc_3),np.median(bias_3)])\n",
    "\n",
    "    temp_heatmap.loc[class_imb] = biases\n",
    "    temp_heatmap_1.loc[class_imb] = biases_1\n",
    "    temp_heatmap_2.loc[class_imb] = biases_2 \n",
    "    temp_heatmap_3.loc[class_imb] = biases_3\n",
    "    acc_heatmap.loc[class_imb] = accuracies\n",
    "    acc_heatmap_1.loc[class_imb] = accuracies_1\n",
    "    acc_heatmap_2.loc[class_imb] = accuracies_2 \n",
    "    acc_heatmap_3.loc[class_imb] = accuracies_3\n",
    "heatmap_DF[\"Test Data\"] = temp_heatmap\n",
    "heatmap_DF[\"SMOTE\"] = temp_heatmap_1\n",
    "heatmap_DF[\"Counterfactual 1\"] = temp_heatmap_2\n",
    "heatmap_DF[\"Counterfactual 2\"] = temp_heatmap_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_incidence = list(range(10, int(MCPc/10)*10+1, 5)) \n",
    "feature_incidence = list(range(10,51,5))\n",
    "heatmap_DF = {}\n",
    "result = []\n",
    "result_2 = []\n",
    "best_model = {}\n",
    "\n",
    "\n",
    "temp_heatmap = pd.DataFrame(columns=feature_incidence)\n",
    "temp_heatmap_2 = pd.DataFrame(columns=feature_incidence)\n",
    "\n",
    "for class_imb in class_incidence:\n",
    "    accuracies = []\n",
    "    biases = []\n",
    "    accuracies_2 = []\n",
    "    biases_2 = []\n",
    "    for feature_imb in feature_incidence:\n",
    "        print((class_imb,feature_imb))\n",
    "            \n",
    "        df_p,df_n = df_subsample_pos_class(synthetic,class_imb)\n",
    "        X,y = add_Fx(df_p,df_n,feature_imb,40)\n",
    "        \n",
    "        acc = []\n",
    "        bias = []\n",
    "        acc_2 = []\n",
    "        bias_2 = []\n",
    "            \n",
    "        for n in range(5):\n",
    "        #progress bar\n",
    "            print(\">> {}\".format(n+1))\n",
    "            \n",
    "            for xx in range(20):\n",
    "                    try:\n",
    "                        Xtrain,Xtest,y_train,y_test = preprocess_data(X,y)\n",
    "                        y_pred,bestparam1 = optimize_model(models,params,Xtrain,Xtest,y_train,y_test,custom_loss_function,10)\n",
    "                        y_pred_2,bestparam2 = optimize_model(models,params,Xtrain,Xtest,y_train,y_test,US_scorer,10)\n",
    "                        break\n",
    "                    except:\n",
    "                        print(\"{} - Division by zero detected!\",format(xx))\n",
    "                        pass   \n",
    "                    \n",
    "\n",
    "            accuracy,bi = evaluate_model(y_test,y_pred,Xtest[:,2].ravel()) \n",
    "            accuracy_2,bi_2 = evaluate_model(y_test,y_pred_2,Xtest[:,2].ravel())\n",
    "            print(\"custom - {}\".format(bestparam1))\n",
    "            print(\"acc - {}\".format(accuracy))\n",
    "            print(\"bias - {}\".format(bi))\n",
    "            print(\"unders - {}\".format(bestparam2))\n",
    "            print(\"acc - {}\".format(accuracy_2))\n",
    "            print(\"bias - {}\".format(bi_2))\n",
    "            \n",
    "            acc.append(accuracy)\n",
    "            bias.append(bi)\n",
    "            acc_2.append(accuracy_2)\n",
    "            bias_2.append(bi_2)\n",
    "            \n",
    "            \n",
    "        accuracies.append(np.median(acc))\n",
    "        biases.append(np.median(bias))\n",
    "        accuracies_2.append(np.median(acc_2))\n",
    "        biases_2.append(np.median(bias_2))\n",
    "        result.append([class_imb,feature_imb,np.median(acc),np.median(bias)])\n",
    "        result_2.append([class_imb,feature_imb,np.median(acc_2),np.median(bias_2)])\n",
    "\n",
    "    temp_heatmap.loc[class_imb] = biases\n",
    "    temp_heatmap2.loc[class_imb] = biases_2\n",
    "heatmap_DF[\"custom\"] = temp_heatmap\n",
    "heatmap_DF[\"underestimation\"] = temp_heatmap_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
